# research-engineering-intern-assignment

# Reddit Analysis Dashboard

## Overview

The Reddit Analysis Dashboard is an analytical tool developed to process and visualize social media data extracted from the subreddits `r/Anarchism`, `r/Conservative`, and `r/Protest`. Leveraging Python, Dash, and machine learning frameworks, this project provides an interactive interface for exploring temporal trends, community distributions, network interactions, and topic evolutions within the collected dataset. Enhanced by AI-driven natural language summaries powered by the Google Gemini API, the dashboard offers both quantitative and qualitative insights into subreddit activity and thematic shifts.

This project was developed as part of the Research Engineering Intern Assignment for SimPPL, adhering to the specified objectives of visualizing insights, applying AI/ML techniques, and deploying an interactive dashboard.

## Features

- **Keyword-Filtered Time Series Analysis**: Utilizes Plotly to generate interactive line graphs, enabling users to filter post frequency by keywords (e.g., "anarchism", "protest") over a specified timeline, revealing temporal patterns such as activity spikes on February 16-17, 2025.
- **Subreddit Distribution Visualization**: Employs a Plotly pie chart to display the proportional contribution of posts across `r/Anarchism`, `r/Conservative`, and `r/Protest`, providing a clear view of community dominance.
- **Dynamic Network Graph**: Implements NetworkX and Plotly to render a keyword-filtered graph of author-subreddit interactions, illustrating connectivity patterns and key contributors within the network.
- **Topic Trend Monitoring**: Applies Latent Dirichlet Allocation (LDA) via scikit-learn to extract topics, visualized as a time series to track their prevalence and evolution.
- **AI-Generated Summaries**: Integrates the Google Gemini API to produce natural language summaries of trends based on user-selected keywords, enhancing accessibility for non-technical users.

## Screenshots

The following screenshots illustrate the dashboard’s functionality:

1. **Time Series Plot**  
   ![Time Series](screenshots/time_series.png)  
   *Interactive line graph displaying post frequency, filterable by keywords, highlighting a peak on February 16-17, 2025.*

2. **Pie Chart**  
   ![Pie Chart](screenshots/pie_chart.png)  
   *Pie chart representing the distribution of posts across subreddits.*

3. **Network Graph**  
   ![Network Graph](screenshots/network_graph.png)  
   *Dynamic visualization of author-subreddit interactions, adjustable by keyword filters.*

4. **Topic Trends**  
   ![Topic Trends](screenshots/topic_trends.png)  
   *Time series plot tracking the prevalence of extracted topics over time.*

5. **Dropdown Options**  
   ![Dropdown](screenshots/dropdown.png)  
   *Dropdown menu offering keyword filtering options, including "All Posts", "Anarchism", "Conservative", and "Protest".*

6. **AI Output**  
   ![AI Data](screenshots/ai_data.png)  
   *Natural language summary generated by the Gemini API, reflecting the selected keyword’s trend.*


## Live Demo

- **Hosted on Render**: [https://reddit-analysis-dashboard.onrender.com](https://reddit-analysis-dashboard.onrender.com)  
  Check it out live—it’s up and running!

## Video Walkthrough

- **Google Drive Link**: [https://drive.google.com/file/d/1xeIrq1HgG07l8QG6yp_jGUmaILk-Q7Io/view?usp=sharing](https://drive.google.com/file/d/1xeIrq1HgG07l8QG6yp_jGUmaILk-Q7Io/view?usp=sharing)  
  Watch me demo the dashboard—see it in action!

## Data Conversion

The raw data came in JSONL format, which wasn’t quite what I needed. So, I wrote a little script—[JSONL-to-JSON-Converter](https://github.com/Siddharth-lal-13/JSONL-to-JSON-Converter)—to turn it into JSON. It’s a simple parser that makes the data fit snugly into my processing pipeline.

## Prerequisites

To deploy or replicate this project, the following prerequisites are required:

- **Python**: Version 3.10, serving as the primary programming language.
- **Machine Learning Frameworks**: Utilized for topic modeling and data processing.
- **Data Science Libraries**: Essential for numerical computation and data manipulation.
- **Git**: Required for version control and repository management.
- **Google Gemini API Key**: Obtainable from [makersuite.google.com](https://makersuite.google.com) under the free tier, necessary for AI-driven summarization.

## Library Dependencies

The project relies on the following Python libraries, with specific versions to ensure compatibility:

- **Local Execution (Embedding Generation)**:
  - `numpy==1.23.5`: Numerical computation library for array operations.
  - `pandas==1.5.3`: Data manipulation and analysis framework.
  - `scikit-learn==1.2.2`: Machine learning library for LDA topic modeling.
  - `tensorflow==2.12.0`: Used for dimensionality reduction (SVD) in topic embedding generation.
  - `plotly==5.14.1`: Interactive visualization library for graphs and charts.
  - `dash==2.9.3`: Web framework for building the interactive dashboard.
  - `networkx==3.1`: Graph theory library for network visualization.
  - `google-geneai`: API client for Gemini-based summarization.
  - `gunicorn==20.1.0`: WSGI server for deployment.

 
## How It Works: Code and Design

Here’s the scoop on how I built this:

- **Code Breakdown**:
  - `data_processing.py`: Loads and preps the JSON data—keeps the messy stuff contained.
  - `visualizations.py`: Cranks out all the graphs with Plotly—time series, pie charts, networks, you name it.
  - `ai_ml.py`: Handles the brainy bits—LDA for topics and Gemini API for summaries.
  - `main.py`: The glue, setting up the Dash app, layout, and callbacks.

- **Why This Way?**: I split it up to keep things manageable—data separate from visuals, ML separate from the frontend. It made debugging a lot less painful, especially when Render threw curveballs like port-binding woes!

- **Thought Process**: Dash was my go-to because it’s Python-based and nails interactive viz with Plotly. The modular design grew out of wanting to keep my sanity as the project got bigger. Gemini API was a slam dunk for summaries—fast and friendly. Render came in when PythonAnywhere’s 512 MB limit choked on my ~488 MB of libraries; its Git setup and extra space were lifesavers.

- **Challenges**: Oh man, the port-binding saga on Render! Gunicorn kept saying `app` wasn’t callable—turns out it needed a proper Dash instance, not some half-baked setup. File paths were tricky too—`os.path` saved the day. Getting the API key right took a few tries, but once it clicked, it was smooth sailing.


- **Deployment (Render)**:
  - Same as above, excluding `tensorflow==2.12.0`, as embeddings are precomputed locally.


## Rationale for Render Selection

Render was chosen over alternatives like PythonAnywhere due to its superior storage capacity and deployment simplicity. PythonAnywhere’s 512 MB limit constrained the inclusion of essential libraries, whereas Render’s free tier supports enough without strict caps, with paid options scaling to 10 GB. Its Git-based deployment eliminates manual file uploads, and the integration of Gunicorn ensures robust WSGI server performance, aligning with the project’s scalability requirements.

## Technical Insights and Analysis

The dashboard elucidates several key insights:

- Temporal Peaks: A significant increase in posting activity on February 16-17, 2025, particularly in r/Anarchism, suggests a response to an external event or discussion catalyst.
- Community Interactions: The network graph reveals clusters of author interactions, indicating cohesive subgroups within subreddits.
- Thematic Evolution: Topic trends demonstrate shifts from ideological discourse to actionable themes, validated by LDA outputs.
- AI Summarization: Gemini API summaries provide concise interpretations, enhancing user understanding without requiring deep data analysis.

## Potential Enhancements

**Future iterations could incorporate:**

- Chatbot Integration: A conversational interface using the Gemini API to query data dynamically.
- Multi-Platform Analysis: Extending data ingestion to include platforms like Twitter for comparative insights.
- Custom Keyword Input: Enhancing the dropdown with a text input for user-defined keyword searches.

## Conclusion

The Reddit Analysis Dashboard exemplifies a blend of data visualization, machine learning, and web deployment, meeting the SimPPL assignment’s objectives. Render’s deployment ensures accessibility and scalability, while the technical stack delivers robust analytical capabilities. This project showcases my ability to transform raw social media data into actionable insights through a user-friendly interface.

Author: Siddharth Lal

Date: March 03, 2025
